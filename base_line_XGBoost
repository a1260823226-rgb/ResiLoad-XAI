"""
é«˜çº§XGBoostæ¨¡å‹ - æ—¶é—´åºåˆ—é¢„æµ‹ä¼˜åŒ–
åŒ…å«é«˜çº§ç‰¹å¾å·¥ç¨‹ã€è¶…å‚æ•°ä¼˜åŒ–å’Œé›†æˆæ–¹æ³•
"""

import pandas as pd
import numpy as np
import warnings
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import pickle
import os

warnings.filterwarnings('ignore')

sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (16, 12)

print("=" * 80)
print("é«˜çº§XGBoostæ¨¡å‹ - æ—¶é—´åºåˆ—é¢„æµ‹ä¼˜åŒ–")
print("=" * 80)
print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ============================================================================
# 1. æ•°æ®åŠ è½½
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤1: åŠ è½½æ•°æ®")
print("=" * 80)

chunk_size = 100000
chunks = []
print("æ­£åœ¨åŠ è½½æ’åºåçš„æ•°æ®...")

try:
    for i, chunk in enumerate(pd.read_csv('data/df_merged_sorted_by_time.csv', chunksize=chunk_size)):
        chunks.append(chunk)
        if (i + 1) % 10 == 0:
            print(f"  å·²åŠ è½½ {(i + 1) * chunk_size:,} è¡Œ...")
    
    df = pd.concat(chunks, ignore_index=True)
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
except FileNotFoundError:
    print("âœ— æ’åºåçš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ check_and_sort_by_time.py")
    exit(1)

# ============================================================================
# 2. é€‰æ‹©å•ä¸ªå˜å‹å™¨
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤2: é€‰æ‹©å˜å‹å™¨")
print("=" * 80)

transformer_counts = df['TRANSFORMER_ID'].value_counts()
selected_transformer = transformer_counts.index[0]
selected_count = transformer_counts.iloc[0]

print(f"é€‰æ‹©æ•°æ®æœ€å¤šçš„å˜å‹å™¨: {selected_transformer}")
print(f"  æ•°æ®è¡Œæ•°: {selected_count:,}")

df = df[df['TRANSFORMER_ID'] == selected_transformer].copy()
df = df.sort_values('DATETIME').reset_index(drop=True)

print(f"âœ“ è¿‡æ»¤åæ•°æ®å½¢çŠ¶: {df.shape}")

# ============================================================================
# 3. é«˜çº§ç‰¹å¾å·¥ç¨‹
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤3: é«˜çº§ç‰¹å¾å·¥ç¨‹")
print("=" * 80)

df['DATETIME'] = pd.to_datetime(df['DATETIME'])

print("æ·»åŠ æ—¶é—´ç‰¹å¾...")

# åŸºç¡€æ—¶é—´ç‰¹å¾
df['Hour'] = df['DATETIME'].dt.hour
df['DayOfWeek'] = df['DATETIME'].dt.dayofweek
df['Month'] = df['DATETIME'].dt.month
df['Day'] = df['DATETIME'].dt.day
df['Quarter'] = df['DATETIME'].dt.quarter
df['DayOfYear'] = df['DATETIME'].dt.dayofyear
df['WeekOfYear'] = df['DATETIME'].dt.isocalendar().week

# å‘¨æœŸç‰¹å¾ï¼ˆä½¿ç”¨sin/cosç¼–ç ï¼‰
df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)
df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)
df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)
df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)
df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['DayOfWeek'] / 7)
df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['DayOfWeek'] / 7)

# å·¥ä½œæ—¥ç‰¹å¾
df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)
df['IsPeakHour'] = df['Hour'].isin([8, 9, 10, 12, 13, 14, 18, 19, 20]).astype(int)
df['IsNightHour'] = df['Hour'].isin([0, 1, 2, 3, 4, 5]).astype(int)
df['IsMorningPeak'] = df['Hour'].isin([7, 8, 9]).astype(int)
df['IsEveningPeak'] = df['Hour'].isin([18, 19, 20]).astype(int)
df['IsOffPeak'] = df['Hour'].isin([23, 0, 1, 2, 3, 4, 5, 6]).astype(int)

print("æ·»åŠ æ»åç‰¹å¾...")

# å¤šå±‚æ¬¡æ»åç‰¹å¾
lags = [1, 2, 3, 6, 12, 24, 48, 72, 168, 336]
for lag in lags:
    df[f'LOAD_lag{lag}'] = df['LOAD'].shift(lag)

print("æ·»åŠ æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾...")

# æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
windows = [6, 12, 24, 48, 168]
for window in windows:
    df[f'LOAD_rolling_mean_{window}'] = df['LOAD'].rolling(window=window, min_periods=1).mean().shift(1)
    df[f'LOAD_rolling_std_{window}'] = df['LOAD'].rolling(window=window, min_periods=1).std().shift(1)
    df[f'LOAD_rolling_min_{window}'] = df['LOAD'].rolling(window=window, min_periods=1).min().shift(1)
    df[f'LOAD_rolling_max_{window}'] = df['LOAD'].rolling(window=window, min_periods=1).max().shift(1)

print("æ·»åŠ å·®åˆ†ç‰¹å¾...")

# å·®åˆ†ç‰¹å¾
df['LOAD_diff1'] = df['LOAD'].diff(1)
df['LOAD_diff24'] = df['LOAD'].diff(24)
df['LOAD_pct_change'] = df['LOAD'].pct_change()

print("æ·»åŠ å¤©æ°”äº¤äº’ç‰¹å¾...")

# å¤©æ°”äº¤äº’ç‰¹å¾
df['TEMP_RH'] = df['TEMP'] * df['RH']
df['TEMP_MXSPD'] = df['TEMP'] * df['MXSPD']
df['TEMP_GUST'] = df['TEMP'] * df['GUST']
df['TEMP_SLP'] = df['TEMP'] * df['SLP']
df['RH_MXSPD'] = df['RH'] * df['MXSPD']
df['TEMP_squared'] = df['TEMP'] ** 2
df['TEMP_cubed'] = df['TEMP'] ** 3
df['TEMP_abs'] = np.abs(df['TEMP'])

print("æ·»åŠ å¤©æ°”æå€¼ç‰¹å¾...")

# å¤©æ°”æå€¼ç‰¹å¾
df['TEMP_range'] = df['MAX'] - df['MIN']
df['TEMP_deviation'] = df['TEMP'] - df['TEMP'].rolling(window=24, min_periods=1).mean()
df['TEMP_trend'] = df['TEMP'].rolling(window=6, min_periods=1).mean().diff()

# å¤„ç†ç¼ºå¤±å€¼
df = df.dropna()

print(f"âœ“ ç‰¹å¾å·¥ç¨‹å®Œæˆ")
print(f"  æ•°æ®å½¢çŠ¶: {df.shape}")
print(f"  ç‰¹å¾æ•°: {len(df.columns) - 3}")

# ============================================================================
# 4. ç‰¹å¾é€‰æ‹©å’Œæ•°æ®ç±»å‹å¤„ç†
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤4: ç‰¹å¾é€‰æ‹©å’Œæ•°æ®ç±»å‹å¤„ç†")
print("=" * 80)

exclude_cols = ['DATETIME', 'TRANSFORMER_ID', 'LOAD']
selected_features = [col for col in df.columns if col not in exclude_cols]

# åªä¿ç•™æ•°å€¼ç‰¹å¾
numeric_features = []
for col in selected_features:
    if df[col].dtype in ['int64', 'float64', 'int32', 'float32']:
        numeric_features.append(col)
    else:
        print(f"  æ’é™¤éæ•°å€¼ç‰¹å¾: {col} (ç±»å‹: {df[col].dtype})")

selected_features = numeric_features
print(f"é€‰æ‹©çš„ç‰¹å¾ ({len(selected_features)}ä¸ª)")

# ============================================================================
# 5. æ•°æ®å‡†å¤‡
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤5: æ•°æ®å‡†å¤‡")
print("=" * 80)

X = df[selected_features].copy()
y = df['LOAD'].copy()

print(f"ç‰¹å¾å½¢çŠ¶: {X.shape}")
print(f"ç›®æ ‡å½¢çŠ¶: {y.shape}")

# ============================================================================
# 6. æ—¶é—´åºåˆ—åˆ†å‰²
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤6: æ—¶é—´åºåˆ—åˆ†å‰²")
print("=" * 80)

train_size = int(0.7 * len(X))
val_size = int(0.15 * len(X))

X_train = X[:train_size]
y_train = y[:train_size]

X_val = X[train_size:train_size + val_size]
y_val = y[train_size:train_size + val_size]

X_test = X[train_size + val_size:]
y_test = y[train_size + val_size:]

print(f"è®­ç»ƒé›†: {X_train.shape[0]:,} æ ·æœ¬")
print(f"éªŒè¯é›†: {X_val.shape[0]:,} æ ·æœ¬")
print(f"æµ‹è¯•é›†: {X_test.shape[0]:,} æ ·æœ¬")

# ============================================================================
# 7. ç‰¹å¾æ ‡å‡†åŒ–
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤7: ç‰¹å¾æ ‡å‡†åŒ–")
print("=" * 80)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

print(f"âœ“ ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ")

# ============================================================================
# 8. XGBoostæ¨¡å‹è®­ç»ƒ - ä¼˜åŒ–å‚æ•°
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤8: XGBoostæ¨¡å‹è®­ç»ƒ - ä¼˜åŒ–å‚æ•°")
print("=" * 80)

# ä¼˜åŒ–çš„XGBoostå‚æ•°
xgb_params = {
    'n_estimators': 500,           # å¢åŠ æ ‘çš„æ•°é‡
    'max_depth': 10,               # å¢åŠ æ ‘çš„æ·±åº¦
    'learning_rate': 0.02,         # é™ä½å­¦ä¹ ç‡ï¼Œæ›´ç²¾ç»†çš„å­¦ä¹ 
    'subsample': 0.9,              # å¢åŠ æ ·æœ¬é‡‡æ ·æ¯”ä¾‹
    'colsample_bytree': 0.9,       # å¢åŠ ç‰¹å¾é‡‡æ ·æ¯”ä¾‹
    'colsample_bylevel': 0.9,      # æ¯å±‚ç‰¹å¾é‡‡æ ·
    'min_child_weight': 1,
    'gamma': 0.1,                  # å¢åŠ åˆ†è£‚æ‰€éœ€çš„æœ€å°æŸå¤±å‡å°‘
    'reg_alpha': 0.05,             # L1æ­£åˆ™åŒ–
    'reg_lambda': 0.5,             # L2æ­£åˆ™åŒ–
    'random_state': 42,
    'n_jobs': -1,
    'verbosity': 1,
    'tree_method': 'hist',         # ä½¿ç”¨ç›´æ–¹å›¾ä¼˜åŒ–
}

try:
    import torch
    if torch.cuda.is_available():
        xgb_params['tree_method'] = 'gpu_hist'
        xgb_params['gpu_id'] = 0
        print("âœ“ ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒ")
except:
    print("âš  ä½¿ç”¨CPUè®­ç»ƒ")

model = xgb.XGBRegressor(**xgb_params)

print(f"\nå¼€å§‹è®­ç»ƒ...")
train_start = datetime.now()

model.fit(
    X_train_scaled, y_train,
    eval_set=[(X_train_scaled, y_train), (X_val_scaled, y_val)],
    eval_metric=['rmse', 'mae'],
    early_stopping_rounds=50,
    verbose=20
)

train_time = (datetime.now() - train_start).total_seconds()
print(f"âœ“ è®­ç»ƒå®Œæˆ (è€—æ—¶: {train_time:.2f}ç§’)")

# ============================================================================
# 9. æ¨¡å‹é¢„æµ‹å’Œè¯„ä¼°
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤9: æ¨¡å‹é¢„æµ‹å’Œè¯„ä¼°")
print("=" * 80)

y_train_pred = model.predict(X_train_scaled)
y_val_pred = model.predict(X_val_scaled)
y_test_pred = model.predict(X_test_scaled)

def calculate_metrics(y_true, y_pred, set_name):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    print(f"\n{set_name}é›†è¯„ä¼°æŒ‡æ ‡:")
    print(f"  RÂ² Score: {r2:.4f}")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  MAE: {mae:.4f}")
    print(f"  MAPE: {mape:.4f}%")
    
    return {'R2': r2, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape}

train_metrics = calculate_metrics(y_train, y_train_pred, "è®­ç»ƒ")
val_metrics = calculate_metrics(y_val, y_val_pred, "éªŒè¯")
test_metrics = calculate_metrics(y_test, y_test_pred, "æµ‹è¯•")

# ============================================================================
# 10. ç”Ÿæˆè¯¦ç»†ç»“æœ
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤10: ç”Ÿæˆè¯¦ç»†ç»“æœ")
print("=" * 80)

def create_detailed_results(y_true, y_pred, set_name):
    error = y_pred - y_true.values
    abs_error = np.abs(error)
    percent_error = np.abs(error) / (np.abs(y_true.values) + 1e-10) * 100
    
    results_df = pd.DataFrame({
        'é¢„æµ‹å€¼': y_pred,
        'çœŸå®å€¼': y_true.values,
        'è¯¯å·®': error,
        'ç»å¯¹è¯¯å·®': abs_error,
        'ç™¾åˆ†æ¯”è¯¯å·®(%)': percent_error,
    })
    
    stats = {
        'é›†åˆ': set_name,
        'æ ·æœ¬æ•°': len(y_true),
        'é¢„æµ‹å€¼_æœ€å¤§': y_pred.max(),
        'é¢„æµ‹å€¼_æœ€å°': y_pred.min(),
        'é¢„æµ‹å€¼_å¹³å‡': y_pred.mean(),
        'é¢„æµ‹å€¼_æå·®': y_pred.max() - y_pred.min(),
        'çœŸå®å€¼_æœ€å¤§': y_true.max(),
        'çœŸå®å€¼_æœ€å°': y_true.min(),
        'çœŸå®å€¼_å¹³å‡': y_true.mean(),
        'çœŸå®å€¼_æå·®': y_true.max() - y_true.min(),
        'è¯¯å·®_å¹³å‡': error.mean(),
        'è¯¯å·®_æœ€å¤§': error.max(),
        'è¯¯å·®_æœ€å°': error.min(),
        'ç»å¯¹è¯¯å·®_å¹³å‡': abs_error.mean(),
        'ç»å¯¹è¯¯å·®_æœ€å¤§': abs_error.max(),
        'ç™¾åˆ†æ¯”è¯¯å·®_å¹³å‡(%)': percent_error.mean(),
        'R2_Score': r2_score(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAE': mean_absolute_error(y_true, y_pred),
        'MAPE': mean_absolute_percentage_error(y_true, y_pred),
    }
    
    return results_df, stats

train_results_df, train_stats = create_detailed_results(y_train, y_train_pred, "è®­ç»ƒé›†")
val_results_df, val_stats = create_detailed_results(y_val, y_val_pred, "éªŒè¯é›†")
test_results_df, test_stats = create_detailed_results(y_test, y_test_pred, "æµ‹è¯•é›†")

print(f"âœ“ è¯¦ç»†ç»“æœè¡¨ç”Ÿæˆå®Œæˆ")

# ============================================================================
# 11. ç‰¹å¾é‡è¦æ€§
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤11: ç‰¹å¾é‡è¦æ€§åˆ†æ")
print("=" * 80)

feature_importance = pd.DataFrame({
    'Feature': selected_features,
    'Importance': model.feature_importances_
}).sort_values('Importance', ascending=False)

print(f"\nTop 20 ç‰¹å¾é‡è¦æ€§:")
for idx, row in feature_importance.head(20).iterrows():
    print(f"  {row['Feature']:40s}: {row['Importance']:.4f}")

# ============================================================================
# 12. ä¿å­˜ç»“æœ
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤12: ä¿å­˜ç»“æœ")
print("=" * 80)

os.makedirs('model_output_advanced', exist_ok=True)

# ä¿å­˜æ¨¡å‹
with open('model_output_advanced/xgboost_advanced.pkl', 'wb') as f:
    pickle.dump(model, f)
print(f"âœ“ æ¨¡å‹å·²ä¿å­˜")

# ä¿å­˜scaler
with open('model_output_advanced/scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print(f"âœ“ Scalerå·²ä¿å­˜")

# ä¿å­˜ç‰¹å¾åˆ—è¡¨
with open('model_output_advanced/features.pkl', 'wb') as f:
    pickle.dump(selected_features, f)
print(f"âœ“ ç‰¹å¾åˆ—è¡¨å·²ä¿å­˜")

# ä¿å­˜è¯¦ç»†ç»“æœ
train_results_df.to_csv('model_output_advanced/train_predictions_detailed.csv', index=False)
val_results_df.to_csv('model_output_advanced/val_predictions_detailed.csv', index=False)
test_results_df.to_csv('model_output_advanced/test_predictions_detailed.csv', index=False)

stats_summary = pd.DataFrame([train_stats, val_stats, test_stats])
stats_summary.to_csv('model_output_advanced/prediction_statistics_summary.csv', index=False)

feature_importance.to_csv('model_output_advanced/feature_importance.csv', index=False)

print(f"âœ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° model_output_advanced/")

# ============================================================================
# 13. å¯è§†åŒ–
# ============================================================================

print("\n" + "=" * 80)
print("æ­¥éª¤13: ç”Ÿæˆå¯è§†åŒ–")
print("=" * 80)

# æ•£ç‚¹å›¾
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for results_df, stats, ax, title in [(train_results_df, train_stats, axes[0], "è®­ç»ƒé›†"),
                                      (val_results_df, val_stats, axes[1], "éªŒè¯é›†"),
                                      (test_results_df, test_stats, axes[2], "æµ‹è¯•é›†")]:
    ax.scatter(results_df['çœŸå®å€¼'], results_df['é¢„æµ‹å€¼'], alpha=0.3, s=1, color='steelblue')
    min_val = min(results_df['çœŸå®å€¼'].min(), results_df['é¢„æµ‹å€¼'].min())
    max_val = max(results_df['çœŸå®å€¼'].max(), results_df['é¢„æµ‹å€¼'].max())
    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='å®Œç¾é¢„æµ‹')
    ax.set_xlabel('çœŸå®å€¼', fontsize=11)
    ax.set_ylabel('é¢„æµ‹å€¼', fontsize=11)
    ax.set_title(f'{title}\n(RÂ² = {stats["R2_Score"]:.4f}, MAE = {stats["MAE"]:.4f})', fontsize=12, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('model_output_advanced/predictions_scatter_plot.png', dpi=300, bbox_inches='tight')
print(f"âœ“ æ•£ç‚¹å›¾å·²ä¿å­˜")
plt.close()

# ç‰¹å¾é‡è¦æ€§
fig, ax = plt.subplots(figsize=(12, 10))
top_features = feature_importance.head(20)
ax.barh(top_features['Feature'], top_features['Importance'], color='steelblue')
ax.set_xlabel('Importance', fontsize=12)
ax.set_title('Top 20 ç‰¹å¾é‡è¦æ€§', fontsize=14, fontweight='bold')
ax.invert_yaxis()
plt.tight_layout()
plt.savefig('model_output_advanced/feature_importance.png', dpi=300, bbox_inches='tight')
print(f"âœ“ ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜")
plt.close()

# ============================================================================
# 14. æ€»ç»“
# ============================================================================

print("\n" + "=" * 80)
print("è®­ç»ƒå®Œæˆæ€»ç»“")
print("=" * 80)

print(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½:")
print(f"  æµ‹è¯•é›† RÂ²: {test_metrics['R2']:.4f}")
print(f"  æµ‹è¯•é›† RMSE: {test_metrics['RMSE']:.4f}")
print(f"  æµ‹è¯•é›† MAE: {test_metrics['MAE']:.4f}")
print(f"  æµ‹è¯•é›† MAPE: {test_metrics['MAPE']:.4f}%")

print(f"\nğŸ“ è¾“å‡ºç›®å½•: model_output_advanced/")

print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)
